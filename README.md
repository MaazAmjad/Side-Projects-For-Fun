# Side-Projects-For-Fun

The purpose is to draw conclusions or analyses in order to utilize better decision-making or analyses based on facts pulled from the datasets.  

The datasets are going to be varied from different websites that is given. 

It will consist of different programming languages.

This repository consists of data that analyzes the following:

Affordable Care Act 
  
To perform analyses on which US states that are uninsured during the years of 2010 and 2015.
  
Education Data
 
Performing data analyses in order to determine which gender performs well, takes advantage of resources, making predictions on which
courses are the most common, and utilize models to predict which one is more accurate based on decision trees, SVM, or confusion matrix.
  
Fake News
  
 Using both Python and R to determine the analyses on Fake News in order to predict which type of news it is by     
 running the decisiontree model in R. 
 The analyses is also done in Python to generate the accuracy of the random forest model. 
  
Global Land Temperatures in Oakland and San Francisco
 
 Using R to predict the differences with the temperatures around these two cities in comparision to the given data back in the early
 history. The analyses involved with converting the latitude and longitude, graphing the average monthly temperature on a celsius
 perspective, uncertainty between today and 100 years ago, and creating a random forest model for both cities.

NFL Draft
 
 Utilized R to predict the performance of draft picks over the last 30 years in order to see which rounds and picks that has performed
 the best in their careers. The analysis is done according to the information on the Quarterback, and Running Backs at that time. 
  
Y Combinator

  Y combinator is a venture capital organization that provides seed money for potential start-ups. Using Python to predict on which 
  organizations and industries that they would invest in.
